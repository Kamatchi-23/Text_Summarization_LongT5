# Text_Summarization_LongT5
This is an experimentation project attempted to explore the text summarization task using Google's Long T5 base model with Tglobal attention mechanism on PubMed Dataset. Considering the limitations of the computation resources and time, the evaluation was constrained to only 1000 test records, which took about 3 hours to obtain the results using T4 GPU. 
